✓ build-nanogpt master ✗ python infer.py log/model_01_38145.pt "Hello, I am a language model"
Using device: mps
/Users/csabapalfi/yc/build-nanogpt/model.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))
/Users/csabapalfi/yc/build-nanogpt/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:332: UserWarning: In MPS autocast, but the target dtype is not supported. Disabling autocast.
MPS Autocast only supports dtype of torch.bfloat16 currently.
  warnings.warn(error_message)
rank 0 sample 0: Hello, I am a language model student. I have three classes and they are one at the middle school in my office. These students are the language teachers,
rank 0 sample 1: Hello, I am a language modeler with a Bachelors in Computer Science. How does a language model software work? It does work if you don't
rank 0 sample 2: Hello, I am a language modeler. This means that you need to be proficient in the language and you need to understand how the people who are in this
rank 0 sample 3: Hello, I am a language modeler! I used to be a part of the language modeler, but for the past 15 years I have been a part
(.venv)
 ✓ build-nanogpt master ✗ python infer.py log/model_01_38145.pt "Hello, I am a language model,"
Using device: mps
/Users/csabapalfi/yc/build-nanogpt/model.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))
/Users/csabapalfi/yc/build-nanogpt/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:332: UserWarning: In MPS autocast, but the target dtype is not supported. Disabling autocast.
MPS Autocast only supports dtype of torch.bfloat16 currently.
  warnings.warn(error_message)
rank 0 sample 0: Hello, I am a language model, which is really not too complicated and it just tells me what the language needs. Why are many of the things that are
rank 0 sample 1: Hello, I am a language model, so how can that be true?
- Any explanation is incomplete because there would have been many discussions with all the users
rank 0 sample 2: Hello, I am a language model, I am working with a language, and I understand the language, so I'll be working in the environment and I can
rank 0 sample 3: Hello, I am a language model, so this is about your language. My class can be used to teach a second language. This is a language model,